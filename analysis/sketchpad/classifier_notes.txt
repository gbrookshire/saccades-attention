
Ridge
- Reduces over-fitting by "shrinking" all model parameters toward 0
	- But they are not exactly zero
- lambda is the shrinkage parameter
	- lambda --> 0: Closer to a standard linear regression
	- Higher lambda corresponds to greater parameter shrinkage
	- In the sklearn function `Ridge`, this is called "alpha"
- Somebody online says it's important to standardize the variables beforehand

LASSO
- Reduces over-fitting by setting all but the most important parameters to 0
	- Also shrinks the parameters that are retained in the model
- Value of lambda determines how many parameters are set to 0
	- lambda --> 0: Closer to a standard linear regression
	- Higher lambda means more parameters are set to zero
	- Some sklearn functions call this parameter `alpha`
- Find the optimal value of lambda by cross-validation
	- Optimal value minimizes the CV error and minimizes model complexity
- Standardize variables beforehand?

Elastic net
- A combination of LASSO and Ridge regression
- alpha determines what the combination is
	- alpha = 0: Ridge
	- alpha = 1: LASSO
	- 0 < alpha < 1: Elastic net regression

Implementation
* sklearn
- Several different functions might be relevant
	- Lasso
		- LassoCV helps select regularization parameter
	- LogisticRegression
		- Some args that might be useful...
		- penalty: l1, l2, elasticnet
		- C: inverse of regularization strength
			- check against inverse of `alpha` in `Lasso`
			- This should have no effect when penalty='none'
			- Smaller values specify stronger regularization
		- solver: can influence speed (and feasibility)
		- multi_class:
			- ovr - binary fit for each label
			- multinomai - predicts specific label
		- max_iter: extend number of iterations to solve
		- l1_ratio: elastic net mixing parameter
		- Choose C and l1_ratio using `LogisticRegressionCV`
	- Look into different ways to score accuracy
		- fit.predict
		- fit.predict_proba
		- fit.score
		- fit.sparsify to get a smaller/faster matrix
* glmnet

Analysis notes
- I'm trying out the analysis on the pilot dataset
- LogisticRegressionCV
    - It works alright with multi_class='multinomai', but not with 'ovr'
        - with 'ovr', it always sets all (or almost all) coefficients to zero
        - and chooses the smallest value of C regardless
    
